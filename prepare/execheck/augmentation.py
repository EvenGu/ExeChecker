import csv
import numpy as np
from tqdm import tqdm
import os
import pickle as pkl
from collections import defaultdict


###### dataset generated by gendata.py #####

def aug_exec_dataset_data(path_data_npy):
    data = np.load(path_data_npy)
    assert len(data.shape) == 5 and data.shape[1] == 3, print(data.shape) # (num_seq, xyz, max_num_frame, num_joints, num_person)
    def mirror_dataset(data):
        num_joints = data.shape[3]
        # print(data[0,:,0,:,0])
        data = data.copy()
        data[:, 0, ...] *= -1 # x-axis
        right_chain = [4, 5, 6, 10, 11, 12]
        left_chain = [7, 8, 9, 13, 14, 15]
        if num_joints == 21: # w/ handfoot
            right_chain += [17, 19]
            left_chain += [18, 20]
        else:
            assert num_joints == 17
        tmp = data[..., right_chain, :]
        data[..., right_chain, :] = data[..., left_chain, :]
        data[..., left_chain, :] = tmp
        return data
    m_data = mirror_dataset(data)
    aug_data = np.concatenate([data, m_data], axis=0)
    print(f'augment dataset DATA from {len(data)} to {len(aug_data)}')
    return aug_data
    
def aug_exec_dataset_labels(path_label_pkl):
    
    sample_names, labels = pkl.load(open(path_label_pkl, 'rb')) # 6-side_step_squat-correct-R1, (8, 1)
    # print(sample_names)
    m_names = ['m'+s for s in sample_names]
    aug_names = sample_names + m_names

    cls3_labels = 'SSLLLLLLLLSRLLSLRRSS' # directions: left,right,symmetrical
    m_cls3_labels = cls3_labels.replace('L', 'r').replace('R','L').replace('r','R')
    # print(m_cls3_labels)
    # exe_list = ['arm_circle', 
    #             'forward_lunge', 
    #             'high_knee_raise', 
    #             'hip_abduction', 
    #             'leg_extension', 
    #             'shoulder_abduction', 
    #             'shoulder_external_rotation', 
    #             'shoulder_flexion', 
    #             'side_step_squat', 
    #             'squat']
    cls3_dict = {'S':0, 'L':1, 'R':2}
    cls1_cls3_map = defaultdict(int)
    m_cls1_cls3_map = defaultdict(int)
    for cls1, cls3 in enumerate(cls3_labels):
        cls1_cls3_map[cls1] = cls3_dict[cls3]
    # print(cls1_cls3_map)
    for cls1, cls3 in enumerate(m_cls3_labels):
        m_cls1_cls3_map[cls1] = cls3_dict[cls3]
    # print(m_cls1_cls3_map)
    cls3_lbls = []
    for i, (cls1, cls2) in enumerate(labels):
        cls3_lbl = (cls1, cls2, cls1_cls3_map[cls1])
        cls3_lbls.append(cls3_lbl)
    m_cls3_lbls = []
    for i, (cls1, cls2) in enumerate(labels):
        cls3_lbl = (cls1, cls2, m_cls1_cls3_map[cls1])
        m_cls3_lbls.append(cls3_lbl)
    aug_lbls = cls3_lbls + m_cls3_lbls
    # sanity check
    assert len(cls3_lbls) == len(m_cls3_lbls)
    for lbl, mlbl in zip(cls3_lbls, m_cls3_lbls):
        assert (lbl[2] + mlbl[2]) % 3 == 0

    print(f'augment dataset LABELS from {len(sample_names)} to {len(aug_lbls)}')
    return aug_names, aug_lbls
        
    
if __name__ == '__main__':
    
    in_dir = '../../processed_execheck'
    out_dir = f'../../processed_execheck_with_SLR'
    folders = [f'xsub_v{i}' for i in range(6)]
    for folder in folders:
        pin = os.path.join(in_dir,folder)
        pout = os.path.join(out_dir,folder)
        os.makedirs(pout, exist_ok=True)
        for file in os.listdir(pin):
            print(file)
            fname, ext = os.path.splitext(file)
            if ext == '.npy':
                aug_data = aug_exec_dataset_data(os.path.join(pin,file))
                np.save(os.path.join(pout,file), aug_data)
            elif ext == '.pkl':
                aug_names, aug_lbls = aug_exec_dataset_labels(os.path.join(pin,file))
                pkl.dump((aug_names, aug_lbls), open(os.path.join(pout,file), 'wb'))



