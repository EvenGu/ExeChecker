import csv
import numpy as np
from tqdm import tqdm
import os
import pickle as pkl
from collections import defaultdict


def ske_vis(data, **kwargs):
    import sys
    sys.path.append('/research/yiwen/ExerciseCheck_HC')
    from dataset.skeleton import vis
    from dataset.uiprmd_skeleton import edge
    vis(data, edge=edge, **kwargs)

###### dataset generated by gendata.py #####

def mirror_dataset(data):
    assert len(data.shape) == 5 and data.shape[1] == 3 and data.shape[-1] == 1, print(data.shape) 
    num_joints = data.shape[3]
    assert num_joints == 17
    # print(data[0,:,0,:,0])
    data = data.copy()
    data[:, 0, ...] *= -1 # x-axis assuming normalized skeleton and midline at x=0
    right_chain = [1,2,3, 14,15,16]
    left_chain = [4,5,6, 11,12,13]
    tmp = data[..., right_chain, 0]
    data[..., right_chain, 0] = data[..., left_chain, 0]
    data[..., left_chain, 0] = tmp
    return data

def aug_uiprmd_dataset_data(path_data_npy, path_label_pkl):

    data = np.load(path_data_npy) # NCTVM: (num_seq, xyz, max_num_frame, num_joints, num_person)
    sample_names, labels = pkl.load(open(path_label_pkl, 'rb')) # 010-DeepSquat-correct-R1, (0, 1)
    num_seq = data.shape[0]
    assert num_seq == len(sample_names)
    
    m_data = mirror_dataset(data) # C,T,V,M
    m_names = ['m'+s for s in sample_names]

    # # for visual check,  
    # ske = np.concatenate([data, m_data], axis=-1)
    # for i in range(num_seq):
    #     ske_vis(ske[i,...], view=1.5, pause=0.001, elev=15, azim=60, title=sample_names[i]) # z-up

    aug_data = np.concatenate([data, m_data], axis=0)
    aug_names = sample_names + m_names
    aug_lbls = labels + labels
    
    return aug_data, aug_names, aug_lbls
        
    
if __name__ == '__main__':
    
    in_dir = 'processed_uiprmd/'
    out_dir = f'processed_uiprmd_with_mirrors'
    for folder in [f'xsub_v{i}' for i in range(10)]:
        pin = os.path.join(in_dir,folder)
        pout = os.path.join(out_dir,folder)
        os.makedirs(pout, exist_ok=True)
        
        for split in ['train', 'val']:
            data_npy = f'seg_data_joint_{split}.npy'
            label_pkl = f'seg_label_{split}.pkl'
            aug_data, aug_names, aug_lbls = aug_uiprmd_dataset_data(
                os.path.join(pin, data_npy), os.path.join(pin, label_pkl))
            np.save(os.path.join(pout, data_npy), aug_data)        
            pkl.dump((aug_names, aug_lbls), open(os.path.join(pout, label_pkl), 'wb'))


